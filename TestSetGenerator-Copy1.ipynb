{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "fe0c89fd-ac4a-4f8b-9acc-43c2750d1c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import os\n",
    "MAX_KEY = int(1e8)\n",
    "\n",
    "# NUM_CONSTRUCTION_INSERTION = int(1e5)\n",
    "NUM_OPERATIONS = [int(1e4), int(5e4), int(1e5), int(5e5), int(1e6)]\n",
    "SET_TYPES = [\"A-I\", \"A-D\", \"A-S\", \"B-I\", \"B-D\", \"B-S\", \"R\"]\n",
    "WEIGHTS = [\n",
    "    [0.10, 0.45, 0.45],\n",
    "    [0.45, 0.10, 0.45],\n",
    "    [0.45, 0.45, 0.10],\n",
    "    [0.80, 0.10, 0.10],\n",
    "    [0.10, 0.80, 0.10],\n",
    "    [0.10, 0.10, 0.80],\n",
    "    [0.33, 0.33, 0.34],\n",
    "]\n",
    "\n",
    "# create all necessary directories\n",
    "if not os.path.exists(f\"testsets\"):\n",
    "    os.mkdir(f\"testsets\")\n",
    "for set_type in SET_TYPES:\n",
    "    # create top directories\n",
    "    if not os.path.exists(f'testsets/{set_type}'):\n",
    "        os.mkdir(f'testsets/{set_type}')\n",
    "    for n_operations in NUM_OPERATIONS:\n",
    "        if not os.path.exists(f\"testsets/{set_type}/{n_operations}\"):\n",
    "            os.mkdir(f\"testsets/{set_type}/{n_operations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d971b18e-b779-44cc-90c5-616e0954bf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "# WARNING: this code takes a very long time to complete. \n",
    "# Expect it to take at least 12 hours or use parallelization.\n",
    "for set_type, weights in zip(SET_TYPES, WEIGHTS):\n",
    "    for n_operations in NUM_OPERATIONS:\n",
    "        for n_iter in range(1, 6):\n",
    "            print(f\"testsets/{set_type}/{n_operations}/iter_{n_iter}.txt\")\n",
    "            # generate the construction insertions\n",
    "            existing_keys = np.random.choice(\n",
    "                np.arange(MAX_KEY) + 1,\n",
    "                size=n_operations,\n",
    "                # size=10,\n",
    "                replace=False\n",
    "            )\n",
    "            sequence = [f\"i {key}\" for key in existing_keys]\n",
    "            for _ in range(n_operations):\n",
    "                operation = np.random.choice(a=3, p=weights)\n",
    "                if (operation == 0):\n",
    "                    # if insertion\n",
    "                    key = np.random.randint(MAX_KEY) + 1\n",
    "                    # make sure to append the key to existing_keys\n",
    "                    np.append(existing_keys, key)\n",
    "                    sequence.append(f\"i {key}\")\n",
    "                elif (operation == 1):\n",
    "                    # if deletion, choose the key to insert from existing_keys\n",
    "                    key = np.random.choice(existing_keys)\n",
    "                    # make sure to remove the key from existing_keys\n",
    "                    np.delete(existing_keys, np.where(existing_keys == key))\n",
    "                    sequence.append(f\"d {key}\")\n",
    "                elif (operation == 2):\n",
    "                    # if search\n",
    "                    key = np.random.randint(MAX_KEY) + 1\n",
    "                    sequence.append(f\"s {key}\")\n",
    "            with open(f\"testsets/{set_type}/{n_operations}/iter_{n_iter}.txt\", \"w\") as f:\n",
    "                for item in sequence:\n",
    "                    f.write(f\"{item}\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "f3f05ac8-9469-417f-8f0a-0bfd1ee2f1de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10000, 50000, 100000, 500000, 1000000, 5000000]"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_OPERATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "204e8838-992f-4c9d-a1cc-21576d743c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testsets/ST-1-N/100000/iter_1.txt\n",
      "testsets/ST-1-N/100000/iter_2.txt\n",
      "testsets/ST-1-N/100000/iter_3.txt\n",
      "testsets/ST-1-N/100000/iter_4.txt\n",
      "testsets/ST-1-N/100000/iter_5.txt\n",
      "testsets/ST-1-N/500000/iter_1.txt\n",
      "testsets/ST-1-N/500000/iter_2.txt\n",
      "testsets/ST-1-N/500000/iter_3.txt\n",
      "testsets/ST-1-N/500000/iter_4.txt\n",
      "testsets/ST-1-N/500000/iter_5.txt\n",
      "testsets/ST-1-N/1000000/iter_1.txt\n",
      "testsets/ST-1-N/1000000/iter_2.txt\n",
      "testsets/ST-1-N/1000000/iter_3.txt\n",
      "testsets/ST-1-N/1000000/iter_4.txt\n",
      "testsets/ST-1-N/1000000/iter_5.txt\n",
      "testsets/ST-1-N/5000000/iter_1.txt\n",
      "testsets/ST-1-N/5000000/iter_2.txt\n",
      "testsets/ST-1-N/5000000/iter_3.txt\n",
      "testsets/ST-1-N/5000000/iter_4.txt\n",
      "testsets/ST-1-N/5000000/iter_5.txt\n",
      "testsets/ST-1-N/10000000/iter_1.txt\n",
      "testsets/ST-1-N/10000000/iter_2.txt\n",
      "testsets/ST-1-N/10000000/iter_3.txt\n",
      "testsets/ST-1-N/10000000/iter_4.txt\n",
      "testsets/ST-1-N/10000000/iter_5.txt\n"
     ]
    }
   ],
   "source": [
    "# Create ST-1-U, ST-1-N\n",
    "for set_type in [\"ST-1-U\", \"ST-1-N\"]:\n",
    "    # create top directories\n",
    "    if not os.path.exists(f'testsets/{set_type}'):\n",
    "        os.mkdir(f'testsets/{set_type}')\n",
    "    for n_operations in NUM_OPERATIONS:\n",
    "        n_operations *= 10\n",
    "        if not os.path.exists(f\"testsets/{set_type}/{n_operations}\"):\n",
    "            os.mkdir(f\"testsets/{set_type}/{n_operations}\")\n",
    "\n",
    "            \n",
    "# ST-1-N\n",
    "for n_operations in NUM_OPERATIONS:\n",
    "    n_operations *= 10\n",
    "    MAX_KEY = int(n_operations / 10)\n",
    "    for n_iter in range(1, 6):\n",
    "        print(f\"testsets/ST-1-N/{n_operations}/iter_{n_iter}.txt\")\n",
    "\n",
    "        # generate float normal random variables and multiply by MAX_KEY\n",
    "        samples = np.random.normal(size = n_operations) * MAX_KEY\n",
    "        # convert to int\n",
    "        samples -= samples.min()\n",
    "        samples = np.array(list(map(int, samples)))\n",
    "        # notmalize the values to make sure it is in the range of [0, MAX_KEY]\n",
    "        samples = MAX_KEY * samples / samples.max()\n",
    "        samples = np.array(list(map(int, samples)))\n",
    "\n",
    "        # convert to search query and save as .txt file\n",
    "        with open(f\"testsets/ST-1-N/{n_operations}/iter_{n_iter}.txt\", \"w\") as f:\n",
    "            for item in np.random.permutation(np.unique(samples)):\n",
    "                f.write(f\"i {item}\\n\")\n",
    "            for item in samples:\n",
    "                f.write(f\"s {item}\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "df87b543-2f55-4f3e-90fd-e158da4fae21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testsets/ST-1-U/100000/iter_1.txt\n",
      "testsets/ST-1-U/100000/iter_2.txt\n",
      "testsets/ST-1-U/100000/iter_3.txt\n",
      "testsets/ST-1-U/100000/iter_4.txt\n",
      "testsets/ST-1-U/100000/iter_5.txt\n",
      "testsets/ST-1-U/500000/iter_1.txt\n",
      "testsets/ST-1-U/500000/iter_2.txt\n",
      "testsets/ST-1-U/500000/iter_3.txt\n",
      "testsets/ST-1-U/500000/iter_4.txt\n",
      "testsets/ST-1-U/500000/iter_5.txt\n",
      "testsets/ST-1-U/1000000/iter_1.txt\n",
      "testsets/ST-1-U/1000000/iter_2.txt\n",
      "testsets/ST-1-U/1000000/iter_3.txt\n",
      "testsets/ST-1-U/1000000/iter_4.txt\n",
      "testsets/ST-1-U/1000000/iter_5.txt\n",
      "testsets/ST-1-U/5000000/iter_1.txt\n",
      "testsets/ST-1-U/5000000/iter_2.txt\n",
      "testsets/ST-1-U/5000000/iter_3.txt\n",
      "testsets/ST-1-U/5000000/iter_4.txt\n",
      "testsets/ST-1-U/5000000/iter_5.txt\n",
      "testsets/ST-1-U/10000000/iter_1.txt\n",
      "testsets/ST-1-U/10000000/iter_2.txt\n",
      "testsets/ST-1-U/10000000/iter_3.txt\n",
      "testsets/ST-1-U/10000000/iter_4.txt\n",
      "testsets/ST-1-U/10000000/iter_5.txt\n"
     ]
    }
   ],
   "source": [
    "# ST-1-U\n",
    "for n_operations in NUM_OPERATIONS:\n",
    "    n_operations *= 10\n",
    "    MAX_KEY = int(n_operations / 10)\n",
    "    for n_iter in range(1, 6):\n",
    "        print(f\"testsets/ST-1-U/{n_operations}/iter_{n_iter}.txt\")\n",
    "\n",
    "        # generate float normal random variables and multiply by MAX_KEY\n",
    "        samples = np.random.random(size = n_operations) * MAX_KEY\n",
    "        # convert to int\n",
    "        samples -= samples.min()\n",
    "        samples = np.array(list(map(int, samples)))\n",
    "        # notmalize the values to make sure it is in the range of [0, MAX_KEY]\n",
    "        samples = MAX_KEY * samples / samples.max()\n",
    "        samples = np.array(list(map(int, samples)))\n",
    "\n",
    "        # convert to search query and save as .txt file\n",
    "        with open(f\"testsets/ST-1-U/{n_operations}/iter_{n_iter}.txt\", \"w\") as f:\n",
    "            for item in np.random.permutation(np.unique(samples)):\n",
    "                f.write(f\"i {item}\\n\")\n",
    "            for item in samples:\n",
    "                f.write(f\"s {item}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "d6e7dad4-74ad-487e-a8ca-f601cb361c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.90 as opposed 100000\n",
      "ratio: 0.00%\n",
      "1.50 as opposed 500000\n",
      "ratio: 0.00%\n",
      "1.56 as opposed 1000000\n",
      "ratio: 0.00%\n",
      "5.22 as opposed 5000000\n",
      "ratio: 0.00%\n",
      "6.46 as opposed 10000000\n",
      "ratio: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# obtain standard deviation of the number of insertion\n",
    "for n_operations in NUM_OPERATIONS:\n",
    "    n_operations *= 10\n",
    "    MAX_KEY = int(n_operations / 10)\n",
    "    num_unique = []\n",
    "    for n_iter in range(10):\n",
    "        # print(f\"testsets/ST-1-N/{n_operations}/iter_{n_iter}.txt\")\n",
    "\n",
    "        # generate float normal random variables and multiply by MAX_KEY\n",
    "        samples = np.random.random(size = n_operations) * MAX_KEY\n",
    "        # convert to int\n",
    "        samples -= samples.min()\n",
    "        samples = np.array(list(map(int, samples)))\n",
    "        # notmalize the values to make sure it is in the range of [0, MAX_KEY]\n",
    "        samples = MAX_KEY * samples / samples.max()\n",
    "        samples = np.array(list(map(int, samples)))\n",
    "        \n",
    "        num_unique.append(len(np.unique(samples)))\n",
    "    std = np.std(num_unique)\n",
    "    print(\"{:.2f} as opposed {}\".format(std, n_operations))\n",
    "    print(\"ratio: {:.2f}%\".format(100*std/n_operations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "6883dc7b-47dc-453a-8c6c-c0e8c93f0192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170.09 as opposed 100000\n",
      "ratio: 0.17%\n",
      "751.14 as opposed 500000\n",
      "ratio: 0.15%\n",
      "1236.81 as opposed 1000000\n",
      "ratio: 0.12%\n",
      "8321.44 as opposed 5000000\n",
      "ratio: 0.17%\n",
      "12080.69 as opposed 10000000\n",
      "ratio: 0.12%\n"
     ]
    }
   ],
   "source": [
    "# obtain standard deviation of the number of insertion\n",
    "for n_operations in NUM_OPERATIONS:\n",
    "    n_operations *= 10\n",
    "    MAX_KEY = int(n_operations / 10)\n",
    "    num_unique = []\n",
    "    for n_iter in range(10):\n",
    "        # print(f\"testsets/ST-1-N/{n_operations}/iter_{n_iter}.txt\")\n",
    "\n",
    "        # generate float normal random variables and multiply by MAX_KEY\n",
    "        samples = np.random.normal(size = n_operations) * MAX_KEY\n",
    "        # convert to int\n",
    "        samples -= samples.min()\n",
    "        samples = np.array(list(map(int, samples)))\n",
    "        # notmalize the values to make sure it is in the range of [0, MAX_KEY]\n",
    "        samples = MAX_KEY * samples / samples.max()\n",
    "        samples = np.array(list(map(int, samples)))\n",
    "        \n",
    "        num_unique.append(len(np.unique(samples)))\n",
    "    std = np.std(num_unique)\n",
    "    print(\"{:.2f} as opposed {}\".format(std, n_operations))\n",
    "    print(\"ratio: {:.2f}%\".format(100*std/n_operations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "7840a462-06cd-4607-bf2a-dd26695355bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create H testset\n",
    "if not os.path.exists(f'testsets/H'):\n",
    "    os.mkdir(f'testsets/H')\n",
    "    for n_operations in NUM_OPERATIONS:\n",
    "        n_operations = int(n_operations / 10)\n",
    "        if not os.path.exists(f\"testsets/H/{n_operations}\"):\n",
    "            os.mkdir(f\"testsets/H/{n_operations}\")\n",
    "\n",
    "for n_operations in NUM_OPERATIONS:\n",
    "    n_operations = int(n_operations / 10)\n",
    "    for n_iter in range(1,6):\n",
    "        existing_keys = np.random.choice(\n",
    "            np.arange(MAX_KEY) + 1,\n",
    "            size=n_operations,\n",
    "            # size=10,\n",
    "            replace=False\n",
    "        )\n",
    "        sequence = [f\"i {key}\" for key in existing_keys]\n",
    "        # insert search operations\n",
    "        for _ in range(n_operations):\n",
    "            key = np.random.randint(MAX_KEY) + 1\n",
    "            sequence.append(f\"s {key}\")\n",
    "        with open(f\"testsets/H/{n_operations}/iter_{n_iter}.txt\", \"w\") as f:\n",
    "            for item in sequence:\n",
    "                f.write(f\"{item}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
